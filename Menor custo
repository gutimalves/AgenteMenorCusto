import numpy as np
class Environment:
    def __init__(self, map, start, goal):  # Definição do ambiente
        self.map = np.array(map)
        self.start = np.array(start)
        self.goal = np.array(goal)
        self.agent_position = np.array(start)
        self.actions = np.array(
            [[1, 0], [-1, 0], [0, 1], [0, -1], [1, 1], [-1, 1], [1, -1], [-1, -1]])  # possiveis movimentos do agente
    def initial_percepts(self):
        available = []
        for a in self.actions:
            pos = self.start + a
            if (0 <= pos[0] < self.map.shape[0]) and (0 <= pos[1] < self.map.shape[1]) and self.map[pos[0]][
                pos[1]] == 0:  # Limite do agente para não sair fora do mapa
                available.append(pos)
        return {'available_positions': available,
                'position': self.agent_position,
                'goal': self.goal}
    def signal(self, action):
        self.agent_position = action['go_to']
        available = []
        for a in self.actions:
            pos = self.agent_position + a
            if (0 <= pos[0] < self.map.shape[0]) and (0 <= pos[1] < self.map.shape[1]) and self.map[pos[0]][
                pos[1]] == 0:
                available.append(pos)
        return {'available_positions': available,
                'position': self.agent_position,
                'goal': self.goal}

class AgentMenorCusto:
    

        
        return []


if __name__ == "__main__":
    map = [[0, 0, 1],
           [1, 0, 1],
           [1, 0, 0]]

    env = Environment(map, [0, 0], [2, 2])

    ag = AgentDFS(env)

    path = ag.act()

    print(path)
